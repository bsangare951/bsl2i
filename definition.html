<!DOCTYPE html>
<html lang="fr">
   <head>
      <title>BIGdata</title>
      <meta charset="utf-8"/>
      <meta name="author" content="BENTAHAR SANGARE"/>
      <meta name="description" content="Explication des bigdata"/>
      <meta name="keywords" content="td1"/>
      <link rel="icon" type="image/png" href="./images/bd3.png"/>
      <link rel="stylesheet" href="styles.css"/>
   </head>
   <body id="top">
      <header>
         <nav>
            <h1><a href="./index.html">BIGdata</a></h1>
            <ul class="nav-menu">
               <li><a href="./index.html">Accueil</a></li>
               <li><a href="./definition.html">Définition</a></li>
               <li><a href="./langages.html">Langages</a></li>
               <li><a href="./utilites.html">Utilités</a></li>
               <li><a href="./conclusion.html">Conclusion</a></li>
            </ul>
         </nav>
         <img src="./images/bigdataAccueil2.png" alt="image accueil" width="150" height="150"/>
         <img src="./images/cyLogo2.png" alt="logo cergy université" width="150" height="150"/>
      </header>
      <main>
         <h2>Définition</h2>
         <section id="6V">
            <h3>Les 6V</h3>
            <p>Le big data désigne un ensemble de technologies, d'outils et de méthodes permettant la collecte, le stockage, 
               le traitement et l’analyse d’un volume massif de données issues de sources diverses. Il se distingue par 6 caractéristiques 
               fondamentales, appelées les 6V :
               <br/>
               Volume : Désigne la quantité énorme de données produites chaque jour, mesurée en téraoctets, pétaoctets ou exaoctets. 
               Ces données proviennent de capteurs, réseaux sociaux, transactions financières, appareils connectés, etc.
               <br/>
               Vitesse : La rapidité à laquelle les données sont générées, capturées et traitées. Certaines applications nécessitent un 
               traitement en temps réel ou quasi-réel, comme les marchés financiers, la cybersécurité ou la gestion du trafic routier.
               <br/>
               Variété : Les données peuvent être de différents types et formats :
               <br/>
               Structurées : Bases de données relationnelles (SQL).
                  <br/>Semi-structurées : JSON, XML, logs.
                  <br/>Non structurées : Vidéos, images, sons, textes, données issues des réseaux sociaux.
               <br/>
               Véracité : La fiabilité et la qualité des données sont essentielles pour garantir des analyses précises. 
               Les données peuvent être bruitées, incomplètes ou biaisées, ce qui nécessite des processus de nettoyage et de validation.
               <br/>
               Valeur : L’objectif du big data est d’extraire des insights exploitables pour optimiser la prise de décision, 
               améliorer l’expérience utilisateur et générer de nouvelles opportunités économiques.
               <br/>
               Variabilité : La signification des données peut évoluer dans le temps, notamment en fonction du contexte et des tendances. 
            </p>
               <figure class="img6V">
               <img src="./images/6V.png" alt="6V" height="150" width="200" />
               <figcaption>Signification des 6V</figcaption>
            </figure>
         </section>
         <p>
            Le big data joue un rôle clé dans l’ère numérique en permettant aux entreprises et aux organisations d’exploiter pleinement le potentiel des données massives. Grâce à ces technologies, il est possible d’identifier des tendances,
            d’optimiser les processus et de prendre des décisions basées sur des analyses précises. Son impact se fait ressentir dans de nombreux domaines, tels que la santé, le commerce, la finance et même les smart cities, où il contribue à améliorer la gestion des ressources et l’expérience utilisateur.
         </p>
         <section class="content">
            <h3>Stockage</h3>
            <p>
               <br/>
               <strong>Collecte et centralisation des données</strong><br/>
               La première étape consiste à collecter les données depuis diverses sources :
               bases de données internes, flux en temps réel, objets connectés ou encore fichiers externes. 
               Ces données doivent ensuite être centralisées dans un système capable de supporter de grandes quantités d’informations,
                tout en assurant leur accessibilité.<br/><br/>
               
               <strong>Organisation et catégorisation des données</strong><br/>
               Une fois les données collectées, il est essentiel de les organiser pour faciliter leur exploitation. Les données peuvent être :<br/>
               - Structurées, comme les tableaux de bases de données ;<br/>
               - Semi-structurées, telles que les fichiers JSON ou XML ;<br/>
               - Non structurées, comme les images, les vidéos ou les documents texte.<br/>
               Chaque catégorie doit être stockée différemment afin d’optimiser l’espace et les performances de recherche.<br/><br/>
               
               <strong>Fragmentation et distribution</strong><br/>
               Pour gérer de grandes quantités de données, il est souvent nécessaire de les diviser en petits morceaux, appelés fragments, 
               et de les stocker sur plusieurs serveurs. Cette méthode, appelée stockage distribué, permet d’améliorer les performances, 
               d’assurer la tolérance aux pannes et de faciliter l’accès aux données à grande échelle.<br/><br/>
               
               <strong>Rédundance et sauvegarde</strong><br/>
               La sécurité et la disponibilité des données sont essentielles. Pour éviter toute perte, 
               il est recommandé de créer plusieurs copies des mêmes données (rédundance) et de les sauvegarder régulièrement. 
               Ainsi, même en cas de panne d’un serveur, les données restent accessibles.<br/><br/>
               
               <strong>Compression et archivage</strong><br/>
               Étant donné le volume élevé des données en Big Data, la compression est utilisée pour réduire la taille des fichiers et 
               optimiser l’espace de stockage. De plus, les données anciennes, moins fréquemment consultées, peuvent être archivées dans 
               des systèmes à moindre coût, tout en restant accessibles si nécessaire.<br/><br/>
               
               <strong>Sécurisation et gouvernance des données</strong><br/>
               Enfin, il est primordial de sécuriser les données stockées. Cela inclut l’utilisation de protocoles d’accès sécurisés, 
               le chiffrement des données sensibles et la mise en place de politiques de gouvernance pour contrôler qui peut accéder aux informations.
            </p>
            <img src="./images/stock.png" alt="stockageImage" height="150" width="200" />
         </section>
      </main>
      <footer>
         <section id="contacter">
            <h3>Nous contacter :<br/></h3>
            <p>
               marwan.bentahar@etu.cyu.fr<br/>
               benoit.sangare@etu.cyu.fr<br/>
            </p>
         </section>
         <section id="hautDePage">
            <h3>Retour en haut de la page</h3>
            <a href="#top" >#</a>
         </section>
         <section id="date">
            <h3>Date :<br/></h3>
            <label>Dernière modification:</label>
            <input type="date" name="date de modification" value="2025-02-06" />
         </section>
      </footer>
   </body>
</html>
